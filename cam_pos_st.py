import openvr
import numpy as np
import math
import cv2

#


# import script_st
# from openstero import pipeline_Openstero_real_depth


def init_openvr():
    """åˆå§‹åŒ–OpenVRç³»ç»Ÿ"""
    global vr_system
    openvr.init(openvr.VRApplication_Background)
    vr_system = openvr.VRSystem()

def shutdown_openvr():
    """å…³é—­OpenVRç³»ç»Ÿ"""
    openvr.shutdown()

"""
get_fov è·å¾—å·¦å³çœ¼çš„æŠ•å½±å‚æ•°å¹¶ä¸”è®¡ç®—æ°´å¹³å’Œå‚ç›´FOVï¼Œè®¡ç®—å·¦çœ¼çš„fovï¼Œé»˜è®¤ä¸ºå…¨å±€fov
calculate_focal_lengthï¼šåˆ©ç”¨fovè®¡ç®—ç„¦è·
get_focal_length_from_steamvrï¼šç»“åˆä¸Šé¢ä¸¤ç§æ–¹æ³•ï¼Œå¾—åˆ°ç„¦è·
"""
def get_fov():
    """ä» SteamVR è·å–å·¦å³çœ¼çš„æ°´å¹³ & å‚ç›´ FOV"""
    openvr.init(openvr.VRApplication_Scene)
    vr_system = openvr.VRSystem()

    # è·å–å·¦çœ¼çš„æŠ•å½±å‚æ•° (left, right, bottom, top)
    left_proj_raw = vr_system.getProjectionRaw(openvr.Eye_Left)
    right_proj_raw = vr_system.getProjectionRaw(openvr.Eye_Right)

    # è®¡ç®— FOVï¼ˆè§’åº¦ï¼‰
    def compute_fov(proj_raw):
        left, right, bottom, top = proj_raw
        fov_h = np.degrees(np.abs(np.arctan(right) - np.arctan(left)))  # æ°´å¹³æ–¹å‘ FOV
        fov_v = np.degrees(np.abs(np.arctan(top) - np.arctan(bottom)))  # å‚ç›´æ–¹å‘ FOV
        return fov_h, fov_v

    FOV_left = compute_fov(left_proj_raw)
    FOV_right = compute_fov(right_proj_raw)

    print(f"ğŸ¯ å·¦çœ¼ FOV: æ°´å¹³ = {FOV_left[0]:.2f}Â°ï¼Œå‚ç›´ = {FOV_left[1]:.2f}Â°")
    print(f"ğŸ¯ å³çœ¼ FOV: æ°´å¹³ = {FOV_right[0]:.2f}Â°ï¼Œå‚ç›´ = {FOV_right[1]:.2f}Â°")

    return {
        "FOV_left": FOV_left,
        "FOV_right": FOV_right
    }

# def calculate_focal_length(FOV_h, FOV_v, screen_width, screen_height):
#     """ä½¿ç”¨ FOV è®¡ç®— VR å¤´æ˜¾çš„ç„¦è· f_x å’Œ f_yï¼ˆå•ä½ï¼šåƒç´ ï¼‰"""
#     # å°†è§’åº¦è½¬æ¢ä¸ºå¼§åº¦
#
#     FOV_h_rad = np.radians(FOV_h)
#     FOV_v_rad = np.radians(FOV_v)
#
#     # è®¡ç®—ç„¦è·
#     f_x = screen_width / (2 * np.tan(FOV_h_rad / 2))
#     f_y = screen_height / (2 * np.tan(FOV_v_rad / 2))
#
#     print(f"ğŸ¯ è®¡ç®—å¾—åˆ°çš„ç„¦è·: f_x = {f_x:.2f} px, f_y = {f_y:.2f} px")
#     return f_x, f_y

"""
è·å–é™æ€å’ŒåŠ¨æ€å‚æ•°
get_oculus_static_paramsï¼šè·å¾—ç³è·ï¼Œå·¦å³çœ¼çŸ©é˜µï¼Œå±å¹•åˆ†è¾¨ç‡
get_hmd_position_and_rotationï¼šè·å¾—å¤´æ˜¾çš„å››å…ƒæ•°
# """

def get_projection():
    # è·å– OpenVR çš„å·¦çœ¼å’Œå³çœ¼æŠ•å½±çŸ©é˜µ
    left_projection = vr_system.getProjectionMatrix(openvr.Eye_Left, 0.1, 100.0)
    right_projection = vr_system.getProjectionMatrix(openvr.Eye_Right, 0.1, 100.0)

    # è½¬æ¢ä¸º NumPy çŸ©é˜µ
    def convert_projection_matrix(projection):
        """ å°† OpenVR è¿”å›çš„ projection ç»“æ„ä½“è½¬æ¢æˆ NumPy 4x4 çŸ©é˜µ """
        projection_np = np.array([
            [projection.m[0][0], projection.m[0][1], projection.m[0][2], projection.m[0][3]],
            [projection.m[1][0], projection.m[1][1], projection.m[1][2], projection.m[1][3]],
            [projection.m[2][0], projection.m[2][1], projection.m[2][2], projection.m[2][3]],
            [projection.m[3][0], projection.m[3][1], projection.m[3][2], projection.m[3][3]]
        ], dtype=np.float32)

        return projection_np

    # åº”ç”¨è½¬æ¢
    left_projection_np = convert_projection_matrix(left_projection)
    right_projection_np = convert_projection_matrix(right_projection)

    return left_projection_np, right_projection_np


# def validate_depth(Z, min_depth=0.1, max_depth=10.0):
#     """éªŒè¯æ·±åº¦å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…"""
#     if not (min_depth <= Z <= max_depth):
#         print(f"è­¦å‘Š: æ·±åº¦å€¼ {Z}m è¶…å‡ºåˆç†èŒƒå›´ [{min_depth}, {max_depth}]m")
#         return False
#     return True

def get_visual_controller_pos():
    # **è·å–æ‰‹æŸ„è®¾å¤‡ç´¢å¼•**
    init_openvr()
    controller_indexes = []
    for i in range(openvr.k_unMaxTrackedDeviceCount):
        if vr_system.getTrackedDeviceClass(i) == openvr.TrackedDeviceClass_Controller:
            controller_indexes.append(i)

    if not controller_indexes:
        print("âŒ æœªæ£€æµ‹åˆ° VR æ‰‹æŸ„")
        return None

    # **è·å–æ‰€æœ‰è®¾å¤‡çš„å§¿æ€ï¼ˆä½ç½® + æ—‹è½¬ï¼‰**
    poses = vr_system.getDeviceToAbsoluteTrackingPose(
        openvr.TrackingUniverseStanding, 0, openvr.k_unMaxTrackedDeviceCount
    )

    for controller_id in controller_indexes:
        pose = poses[controller_id]
        if controller_id == 1:
            # **è§£æä½ç½® (x, y, z)**
            matrix = pose.mDeviceToAbsoluteTracking
            x, y, z = matrix[0][3], matrix[1][3], matrix[2][3]
            return (x, y, z)

def calculate_world_position_2(
        left_point: np.ndarray,  # å·¦çœ¼2Dç‚¹åæ ‡ [x, y]
        right_point: np.ndarray,  # å³çœ¼2Dç‚¹åæ ‡ [x, y]
        left_projection: np.ndarray,  # å·¦çœ¼æŠ•å½±çŸ©é˜µ (4x4)
        right_projection: np.ndarray,  # å³çœ¼æŠ•å½±çŸ©é˜µ (4x4)
        left_eye_to_head: np.ndarray,  # å·¦çœ¼åˆ°å¤´éƒ¨å˜æ¢çŸ©é˜µ (4x4)
        right_eye_to_head: np.ndarray,  # å³çœ¼åˆ°å¤´éƒ¨å˜æ¢çŸ©é˜µ (4x4)
        hmd_to_world: np.ndarray  # HMDåˆ°ä¸–ç•Œç©ºé—´å˜æ¢çŸ©é˜µ (4x4)
) -> np.ndarray:
    """
    ä½¿ç”¨è§†å·®ç›´æ¥è®¡ç®—VRä¸­ç‚¹çš„æ·±åº¦å’Œä¸–ç•Œåæ ‡
    """
    # 1. è·å–å·¦å³çœ¼åœ¨å¤´éƒ¨ç©ºé—´ä¸­çš„ä½ç½®
    left_eye_origin = np.array([0.0, 0.0, 0.0, 1.0])
    right_eye_origin = np.array([0.0, 0.0, 0.0, 1.0])

    left_eye_head = left_eye_to_head @ left_eye_origin
    right_eye_head = right_eye_to_head @ right_eye_origin

    # å½’ä¸€åŒ–
    left_eye_head /= left_eye_head[3]
    right_eye_head /= right_eye_head[3]

    # 2. è®¡ç®—ä¸¤çœ¼é—´è·
    eye_separation = np.linalg.norm(right_eye_head[:3] - left_eye_head[:3])

    # 3. å°†2Dç‚¹è½¬æ¢ä¸ºçœ¼ç›ç©ºé—´ä¸­çš„æ–¹å‘å‘é‡
    # å·¦çœ¼
    left_ndc = np.array([left_point[0], left_point[1], -1.0, 1.0])
    left_eye_dir = np.linalg.inv(left_projection) @ left_ndc
    left_eye_dir /= left_eye_dir[3]
    left_eye_dir = left_eye_dir[:3] - np.array([0.0, 0.0, 0.0])  # æ–¹å‘å‘é‡
    left_eye_dir /= np.linalg.norm(left_eye_dir)  # å•ä½åŒ–

    # å³çœ¼
    right_ndc = np.array([right_point[0], right_point[1], -1.0, 1.0])
    right_eye_dir = np.linalg.inv(right_projection) @ right_ndc
    right_eye_dir /= right_eye_dir[3]
    right_eye_dir = right_eye_dir[:3] - np.array([0.0, 0.0, 0.0])  # æ–¹å‘å‘é‡
    right_eye_dir /= np.linalg.norm(right_eye_dir)  # å•ä½åŒ–

    # 4. å°†æ–¹å‘å‘é‡è½¬æ¢åˆ°å¤´éƒ¨ç©ºé—´
    # åˆ›å»ºæ–¹å‘ç‚¹ (w=0 è¡¨ç¤ºæ–¹å‘å‘é‡)
    left_dir_point = np.array([left_eye_dir[0], left_eye_dir[1], left_eye_dir[2], 0.0])
    right_dir_point = np.array([right_eye_dir[0], right_eye_dir[1], right_eye_dir[2], 0.0])

    # å˜æ¢æ–¹å‘å‘é‡åˆ°å¤´éƒ¨ç©ºé—´
    left_head_dir = left_eye_to_head @ left_dir_point
    right_head_dir = right_eye_to_head @ right_dir_point

    # å½’ä¸€åŒ–æ–¹å‘å‘é‡
    left_head_dir = left_head_dir[:3]
    right_head_dir = right_head_dir[:3]
    left_head_dir /= np.linalg.norm(left_head_dir)
    right_head_dir /= np.linalg.norm(right_head_dir)
    # 5. ä½¿ç”¨è§†å·®å…¬å¼è®¡ç®—æ·±åº¦
    # è®¡ç®—è§†çº¿å¤¹è§’ï¼ˆå¼§åº¦ï¼‰
    cos_angle = np.dot(left_head_dir, right_head_dir)
    angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))
    # è§†å·®å…¬å¼: æ·±åº¦ = çœ¼é—´è· / (2 * tan(è§†å·®è§’/2))
    # è§†å·®è§’å°±æ˜¯è§†çº¿å¤¹è§’
    depth = eye_separation / (2 * np.tan(angle / 2))
    # 6. è®¡ç®—å¤´éƒ¨ç©ºé—´ä¸­çš„ç‚¹ä½ç½®
    # ä½¿ç”¨å·¦çœ¼å°„çº¿æ–¹å‘å’Œè®¡ç®—å‡ºçš„æ·±åº¦
    head_point = left_eye_head[:3] + depth * left_head_dir
    # 7. å˜æ¢åˆ°ä¸–ç•Œç©ºé—´
    # æ„é€ é½æ¬¡åæ ‡
    head_point_homogeneous = np.array([head_point[0], head_point[1], head_point[2], 1.0])
    # å˜æ¢åˆ°ä¸–ç•Œç©ºé—´
    world_point_homogeneous = hmd_to_world @ head_point_homogeneous
    # å½’ä¸€åŒ–
    world_point_homogeneous /= world_point_homogeneous[3]
    # å–å‰ä¸‰ç»´
    world_point = world_point_homogeneous[:3]
    return world_point

# def calculate_world_position(
#         left_point: np.ndarray,  # å·¦çœ¼2Dç‚¹åæ ‡ [x, y]
#         right_point: np.ndarray,  # å³çœ¼2Dç‚¹åæ ‡ [x, y]
#         left_projection: np.ndarray,  # å·¦çœ¼æŠ•å½±çŸ©é˜µ (4x4)
#         right_projection: np.ndarray,  # å³çœ¼æŠ•å½±çŸ©é˜µ (4x4)
#         left_eye_to_head: np.ndarray,  # å·¦çœ¼åˆ°å¤´éƒ¨å˜æ¢çŸ©é˜µ (4x4)
#         right_eye_to_head: np.ndarray,  # å³çœ¼åˆ°å¤´éƒ¨å˜æ¢çŸ©é˜µ (4x4)
#         hmd_to_world: np.ndarray  # HMDåˆ°ä¸–ç•Œç©ºé—´å˜æ¢çŸ©é˜µ (4x4)
# ) -> np.ndarray:
#     """
#     è®¡ç®—VRä¸­æŸä¸ªç‚¹åœ¨ä¸–ç•Œç©ºé—´ä¸­çš„3Dåæ ‡
#
#     å‚æ•°:
#     - left_point: å·¦çœ¼ä¸­çœ‹åˆ°çš„2Dç‚¹åæ ‡ [x, y]ï¼ŒèŒƒå›´[-1, 1]
#     - right_point: å³çœ¼ä¸­çœ‹åˆ°çš„2Dç‚¹åæ ‡ [x, y]ï¼ŒèŒƒå›´[-1, 1]
#     - left_projection: å·¦çœ¼æŠ•å½±çŸ©é˜µ
#     - right_projection: å³çœ¼æŠ•å½±çŸ©é˜µ
#     - left_eye_to_head: å·¦çœ¼åˆ°HMDå˜æ¢çŸ©é˜µ
#     - right_eye_to_head: å³çœ¼åˆ°HMDå˜æ¢çŸ©é˜µ
#     - hmd_to_world: HMDåˆ°ä¸–ç•Œç©ºé—´å˜æ¢çŸ©é˜µ
#
#     è¿”å›:
#     - world_point: ç‚¹åœ¨ä¸–ç•Œç©ºé—´ä¸­çš„3Dåæ ‡ [x, y, z]
#     """
#     print("-------calculate world postion-----------------------")
#     print("left_point",left_point)
#     print("right_point",right_point)
#     print("left_projection", left_projection)#åˆ—ä¸»åºçš„leftã€‚æ˜¯æ­£ç¡®çš„
#     print("right_projection",right_projection)#åˆ—ä¸»åºçš„rightã€‚æ˜¯æ­£ç¡®çš„
#     print("left_eye_to_head",left_eye_to_head)
#     print("right_eye_to_head",right_eye_to_head)
#     print("hmd_to_world",hmd_to_world)
#
#     def get_ray_from_eye_with_planes(point_2d, projection, eye_to_head, hmd_to_world,z_near=0.1,z_far=100,
#                                      ):
#         """
#         ä» 2D å½’ä¸€åŒ–åæ ‡ç‚¹ï¼Œåˆ©ç”¨è¿‘è£å‰ªé¢(z_near)å’Œè¿œè£å‰ªé¢(z_far)åæŠ•å½±ä¸º
#         ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ä¸€æ¡å°„çº¿ (ray_origin, ray_direction)
#         """
#
#         # 1. æ„é€  è¿‘å¹³é¢ å’Œ è¿œå¹³é¢ ä¸Šçš„ 4D é½æ¬¡åæ ‡
#         point_near = np.array([point_2d[0], point_2d[1], z_near, 1.0])
#         point_far = np.array([point_2d[0], point_2d[1], z_far, 1.0])
#
#         # 2. æŠ•å½±çŸ©é˜µæ±‚é€†ï¼ŒåæŠ•å½±åˆ° çœ¼ç›ç©ºé—´
#         inv_proj = np.linalg.inv(projection)
#         eye_near = inv_proj @ point_near
#         eye_far = inv_proj @ point_far
#
#         # é½æ¬¡åæ ‡å½’ä¸€åŒ– (ç¬¬å››åˆ†é‡ w ä¸ä¸€å®šæ˜¯1ï¼Œéœ€è¦é™¤ä»¥ w)
#         eye_near /= eye_near[3]
#         eye_far /= eye_far[3]
#
#         # 3. è®¡ç®—åœ¨çœ¼ç›ç©ºé—´çš„å°„çº¿æ–¹å‘ (eye_ray_dir)
#         #    å…ˆæ±‚å·®ï¼Œå†åªå–å‰3ç»´åšå½’ä¸€åŒ–
#         eye_ray_dir = eye_far - eye_near
#         eye_ray_dir = eye_ray_dir[:3] / np.linalg.norm(eye_ray_dir[:3])
#
#         # 4. å°† near ç‚¹è½¬æ¢åˆ°å¤´éƒ¨åæ ‡
#         head_near = eye_to_head @ eye_near
#         head_near /= head_near[3]
#
#         # å†è½¬æ¢åˆ°ä¸–ç•Œåæ ‡
#         world_near = hmd_to_world @ head_near
#         world_near /= world_near[3]
#
#         # 5. å°† far ç‚¹ ä¹Ÿè½¬æ¢åˆ°ä¸–ç•Œåæ ‡
#         head_far = eye_to_head @ eye_far
#         head_far /= head_far[3]
#         world_far = hmd_to_world @ head_far
#         world_far /= world_far[3]
#
#         # 6. ç”¨ world_far å’Œ world_near çš„å·® æ¥ç¡®å®šå°„çº¿æ–¹å‘
#         ray_origin = world_near[:3]  # å–é½æ¬¡åæ ‡å‰3ç»´
#         ray_direction = world_far[:3] - world_near[:3]
#         ray_direction = ray_direction / np.linalg.norm(ray_direction)
#
#         return ray_origin, ray_direction
#
#     # è·å–ä¸¤æ¡å°„çº¿
#     left_origin, left_dir = get_ray_from_eye_with_planes(
#         left_point, left_projection, left_eye_to_head, hmd_to_world
#     )
#     right_origin, right_dir = get_ray_from_eye_with_planes(
#         right_point, right_projection, right_eye_to_head, hmd_to_world
#     )
#
#     # è®¡ç®—ä¸¤æ¡å°„çº¿çš„æœ€è¿‘ç‚¹
#     u = left_dir
#     v = right_dir
#     p0 = left_origin
#     p1 = right_origin
#
#     a = np.dot(u, u)
#     b = np.dot(u, v)
#     c = np.dot(v, v)
#     d = np.dot(u, p0 - p1)
#     e = np.dot(v, p0 - p1)
#
#     # è®¡ç®—å‚æ•°
#     s = (b * e - c * d) / (a * c - b * b)
#     t = (a * e - b * d) / (a * c - b * b)
#
#     # è®¡ç®—æœ€è¿‘ç‚¹
#     p_left = p0 + s * u
#     p_right = p1 + t * v
#
#     # å–ä¸­ç‚¹ä½œä¸ºæœ€ç»ˆçš„3Dä½ç½®
#     world_point = (p_left + p_right) / 2
#
#     return world_point

def eye_to_head():
    # 1è·å– å·¦çœ¼ åˆ° HMD å˜æ¢çŸ©é˜µ
    left_eye_to_head = vr_system.getEyeToHeadTransform(openvr.Eye_Left)

    # 2ï¸ è·å– å³çœ¼ åˆ° HMD å˜æ¢çŸ©é˜µ
    right_eye_to_head = vr_system.getEyeToHeadTransform(openvr.Eye_Right)


    # 3ï¸ è½¬æ¢ä¸º NumPy çŸ©é˜µ
    def convert_transform(mat):
        return np.array([
            [mat[0][0], mat[0][1], mat[0][2], mat[0][3]],
            [mat[1][0], mat[1][1], mat[1][2], mat[1][3]],
            [mat[2][0], mat[2][1], mat[2][2], mat[2][3]],
            [0, 0, 0, 1]
        ])

    left_eye_to_head_matrix = convert_transform(left_eye_to_head)
    right_eye_to_head_matrix = convert_transform(right_eye_to_head)

    # 4ï¸ æ‰“å°ç»“æœ
    return left_eye_to_head_matrix,right_eye_to_head_matrix

def hmd_to_world():
    #  è·å– HMD çš„ä¸–ç•Œå˜æ¢çŸ©é˜µ
    poses = vr_system.getDeviceToAbsoluteTrackingPose(
        openvr.TrackingUniverseStanding, 0, openvr.k_unMaxTrackedDeviceCount
    )

    #  HMD ä½äºç´¢å¼• `openvr.k_unTrackedDeviceIndex_Hmd`
    pose = poses[openvr.k_unTrackedDeviceIndex_Hmd]


    hmd_to_world_matrix = np.array([
        [pose.mDeviceToAbsoluteTracking[0][0], pose.mDeviceToAbsoluteTracking[0][1],
         pose.mDeviceToAbsoluteTracking[0][2], pose.mDeviceToAbsoluteTracking[0][3]],
        [pose.mDeviceToAbsoluteTracking[1][0], pose.mDeviceToAbsoluteTracking[1][1],
         pose.mDeviceToAbsoluteTracking[1][2], pose.mDeviceToAbsoluteTracking[1][3]],
        [pose.mDeviceToAbsoluteTracking[2][0], pose.mDeviceToAbsoluteTracking[2][1],
         pose.mDeviceToAbsoluteTracking[2][2], pose.mDeviceToAbsoluteTracking[2][3]],
        [0, 0, 0, 1]  # é½æ¬¡åæ ‡
    ])
    # print("hmd_to_world function", hmd_to_world_matrix)
    return hmd_to_world_matrix

def calculate_3d_pos(cxl, cxr, cyl, cyr):
    # è¿™äº›çŸ©é˜µéœ€è¦ä»SteamVR APIè·å–
    #æŠ•å½±çŸ©é˜µ
    left_projection, right_projection = get_projection()

    # å½’ä¸€åŒ–2Dç‚¹åæ ‡
    left_point = np.array([cxl,cyl])
    right_point = np.array([cxr, cyr])

    #hmd to head and hmd to world
    left_eye_to_head_matrix, right_eye_to_head_matrix = eye_to_head()
    hmd_to_world_matrix = hmd_to_world()

    world_pos = calculate_world_position_2(#projectionä»¥ä¸‹å…¨éƒ¨åŸºäºç±³
        left_point, right_point,
        left_projection, right_projection,
        left_eye_to_head_matrix, right_eye_to_head_matrix,
        hmd_to_world_matrix
    )

    print(f"ä¸–ç•Œåæ ‡: {world_pos}")
    return world_pos


"""
åŸºäºopenstereoæ¥è¿›è¡Œæ·±åº¦è®¡ç®—ï¼Œleftåæ ‡å³æ˜¯è§†å·®å›¾åæ ‡
è¿”å›è¯¥ç‚¹çš„å®é™…æ·±åº¦
"""
def calculate_3d_pos_2(cxl, cxr, cyl, cyr):
    # è¿™äº›çŸ©é˜µéœ€è¦ä»SteamVR APIè·å–
    #æŠ•å½±çŸ©é˜µ
    # left_projection, right_projection = get_projection()
    #
    # # å½’ä¸€åŒ–2Dç‚¹åæ ‡
    # left_point = np.array([cxl,cyl])
    # right_point = np.array([cxr, cyr])

    # #hmd to head and hmd to world
    # left_eye_to_head_matrix, right_eye_to_head_matrix = eye_to_head()
    # hmd_to_world_matrix = hmd_to_world()
    #
    # world_pos = calculate_world_position_2(#projectionä»¥ä¸‹å…¨éƒ¨åŸºäºç±³
    #     left_point, right_point,
    #     left_projection, right_projection,
    #     left_eye_to_head_matrix, right_eye_to_head_matrix,
    #     hmd_to_world_matrix
    # )
    focal_length, baseline, max_disp_default = get_vr_camera_parameters()

    real_depth = pipeline_Openstero_real_depth(baseline, focal_length, (cxl,cyl))

    print(f"å®é™…æ·±åº¦: {real_depth}")
    return real_depth

def get_hmd_forward_vector():
    """
    ä½¿ç”¨ OpenVR è·å– HMD çš„å§¿æ€ï¼Œå¹¶è¿”å›ä¸€ä¸ªç›¸å¯¹äºå¤´ç›”å‰å‘çš„å•ä½å‘é‡ã€‚
    å‚è€ƒå‘é‡ [0, 0, -1] è¡¨ç¤ºå¤´ç›”é»˜è®¤çš„å‰æ–¹ï¼ˆæ³¨æ„ï¼šæ ¹æ®ä½ çš„ç³»ç»Ÿï¼Œå‰æ–¹å¯èƒ½æœ‰æ‰€ä¸åŒï¼‰ã€‚
    """
    # åˆå§‹åŒ– OpenVR
    openvr.init(openvr.VRApplication_Scene)
    vr_system = openvr.VRSystem()

    # è·å–æ‰€æœ‰è®¾å¤‡çš„å§¿æ€
    poses = vr_system.getDeviceToAbsoluteTrackingPose(
        openvr.TrackingUniverseStanding, 0, openvr.k_unMaxTrackedDeviceCount
    )

    hmd_pose = poses[openvr.k_unTrackedDeviceIndex_Hmd]
    if not hmd_pose.bPoseIsValid:
        print("HMD å§¿æ€æ— æ•ˆ")
        openvr.shutdown()
        return None

    # è·å– HMD çš„ 3x4 å§¿æ€çŸ©é˜µï¼Œå¹¶è½¬æ¢ä¸º 4x4 çŸ©é˜µ
    m = hmd_pose.mDeviceToAbsoluteTracking
    mat = np.array([
        [m[0][0], m[0][1], m[0][2], m[0][3]],
        [m[1][0], m[1][1], m[1][2], m[1][3]],
        [m[2][0], m[2][1], m[2][2], m[2][3]],
        [0.0, 0.0, 0.0, 1.0]
    ])

    # æå–æ—‹è½¬éƒ¨åˆ†ï¼ˆå·¦ä¸Š 3x3 çŸ©é˜µï¼‰
    rot_matrix = mat[:3, :3]

    # å‚è€ƒå‘é‡ [0, 0, -1]ï¼Œè¡¨ç¤ºå¤´ç›”é»˜è®¤çš„æ­£å‰æ–¹
    ref_forward = np.array([0, 0, -1])

    # è®¡ç®—å½“å‰å‰å‘ï¼šæ—‹è½¬çŸ©é˜µä¹˜ä»¥å‚è€ƒå‘é‡
    forward = rot_matrix.dot(ref_forward)

    # å½’ä¸€åŒ–å¾—åˆ°å•ä½å‘é‡
    norm = np.linalg.norm(forward)
    if norm != 0:
        forward_unit = forward / norm
    else:
        forward_unit = forward

    openvr.shutdown()
    return forward_unit* 0.1

#
def get_vr_camera_parameters(max_disp_default=192):
    """
    ä½¿ç”¨ OpenVR è·å– VR ç¯å¢ƒä¸‹çš„ç›¸æœºå‚æ•°ï¼š
      - focal_lengthï¼šä¼°è®¡å·¦çœ¼æŠ•å½±çŸ©é˜µ m[0][0]ï¼Œä½œä¸ºç„¦è·ï¼ˆå•ä½ï¼šåƒç´ ï¼‰
      - baselineï¼šå·¦å³çœ¼ä¹‹é—´çš„è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰
      - max_dispï¼šæœ€å¤§è§†å·®å€¼ï¼ˆé€šå¸¸å–è®­ç»ƒé…ç½®å€¼ï¼Œè¿™é‡Œç›´æ¥è¿”å›é»˜è®¤å€¼ï¼‰

    è¿”å›ï¼š
      (focal_length, baseline, max_disp)
    """
    # åˆå§‹åŒ– OpenVR
    openvr.init(openvr.VRApplication_Scene)
    vr_system = openvr.VRSystem()

    # --- è·å–ç„¦è· ---
    # è®¾ç½®è¿‘è£å‰ªé¢å’Œè¿œè£å‰ªé¢å‚æ•°
    near = 0.1
    far = 1000.0
    # è·å–å·¦çœ¼æŠ•å½±çŸ©é˜µï¼Œè¿”å›ä¸€ä¸ª HmdMatrix44_t å¯¹è±¡
    left_proj = vr_system.getProjectionMatrix(openvr.Eye_Left, near, far)
    # å°†å…¶è½¬æ¢ä¸º 4x4 çš„ NumPy æ•°ç»„
    left_proj_mat = np.array([
        [left_proj.m[0][0], left_proj.m[0][1], left_proj.m[0][2], left_proj.m[0][3]],
        [left_proj.m[1][0], left_proj.m[1][1], left_proj.m[1][2], left_proj.m[1][3]],
        [left_proj.m[2][0], left_proj.m[2][1], left_proj.m[2][2], left_proj.m[2][3]],
        [left_proj.m[3][0], left_proj.m[3][1], left_proj.m[3][2], left_proj.m[3][3]]
    ], dtype=np.float32)
    # è¿™é‡Œæˆ‘ä»¬å‡è®¾ left_proj_mat[0,0] è¿‘ä¼¼ä»£è¡¨ç„¦è·ï¼ˆåƒç´ ï¼‰
    focal_length = left_proj_mat[0, 0]

    # --- è·å–åŸºçº¿ï¼ˆå·¦å³çœ¼è·ç¦»ï¼‰ ---
    # è·å–å·¦å³çœ¼åˆ°å¤´éƒ¨çš„å˜æ¢çŸ©é˜µ
    left_transform = vr_system.getEyeToHeadTransform(openvr.Eye_Left)
    right_transform = vr_system.getEyeToHeadTransform(openvr.Eye_Right)

    def convert_openvr_matrix(mat):
        return np.array([
            [mat.m[0][0], mat.m[0][1], mat.m[0][2], mat.m[0][3]],
            [mat.m[1][0], mat.m[1][1], mat.m[1][2], mat.m[1][3]],
            [mat.m[2][0], mat.m[2][1], mat.m[2][2], mat.m[2][3]],
            [0.0, 0.0, 0.0, 1.0]
        ], dtype=np.float32)

    left_mat = convert_openvr_matrix(left_transform)
    right_mat = convert_openvr_matrix(right_transform)
    # æå–å¹³ç§»å‘é‡ï¼ˆçœ¼ç›ä½ç½®ï¼‰ï¼Œä¸€èˆ¬åœ¨çŸ©é˜µçš„æœ€åä¸€åˆ—
    left_pos = left_mat[:3, 3]
    right_pos = right_mat[:3, 3]
    # è®¡ç®—å·¦å³çœ¼ä½ç½®çš„æ¬§æ°è·ç¦»ï¼Œä½œä¸ºåŸºçº¿ï¼ˆå•ä½ï¼šç±³ï¼‰
    baseline = np.linalg.norm(right_pos - left_pos)

    # å…³é—­ OpenVR
    openvr.shutdown()

    return focal_length, baseline, max_disp_default


"""
Intrinsic_Parametersè¿”å›å†…å‚çŸ©é˜µkï¼ŒStereo_rectificationè¿›è¡ŒåŒç›®ç«‹ä½“æ ¡æ­£ï¼Œå…ˆæ ¡æ­£å†åšåˆ«çš„
"""
def Intrinsic_Parameters(horizontal_FOV, vertical_FOV, image_width, image_height):
    """
    Computes the intrinsic camera matrix (K) from the horizontal and vertical FOV and image size.
    """
    hFOV_rad = math.radians(horizontal_FOV)
    vFOV_rad = math.radians(vertical_FOV)
    # Compute focal lengths using: f = (w/2) / tan(horizontal_FOV/2)
    f_x = (image_width / 2.0) / math.tan(hFOV_rad / 2)
    f_y = (image_height / 2.0) / math.tan(vFOV_rad / 2)
    cx = image_width / 2.0
    cy = image_height / 2.0

    K = np.array([
        [f_x, 0,   cx],
        [0,   f_y, cy],
        [0,   0,   1]
    ], dtype=np.float32)
    return K

def Stereo_rectification(right_image,left_image):
    fov = get_fov()
    # ç«‹ä½“æ ¡æ­£ï¼Œå†…å‚å’Œç•¸å˜ç³»æ•°ï¼Œæ— ç•¸å˜
    hFOV_left, vFOV_left = fov["FOV_left"]
    hFOV_right, vFOV_right = fov["FOV_right"]

    dist_left = np.zeros((5, 1), dtype=np.float32)
    dist_right = np.zeros((5, 1), dtype=np.float32)

    # 3. æ ¹æ®å›¾åƒå°ºå¯¸è®¡ç®—å†…å‚çŸ©é˜µ
    image_height, image_width = left_image.shape[:2]
    image_size = (image_width, image_height)
    K_left = Intrinsic_Parameters(hFOV_left, vFOV_left, image_width, image_height)
    K_right = Intrinsic_Parameters(hFOV_right, vFOV_right, image_width, image_height)

    # è®¡ç®—å·¦å³çœ¼ä¹‹é—´çš„ç›¸å¯¹å˜æ¢çŸ©é˜µï¼šä»å³çœ¼åˆ°å·¦çœ¼
    left_eye_to_head_matrix, right_eye_to_head_matrix = eye_to_head()
    relative_transform = np.linalg.inv(right_eye_to_head_matrix) @ left_eye_to_head_matrix

    # æå–æ—‹è½¬çŸ©é˜µ R å’Œå¹³ç§»å‘é‡ T
    R = relative_transform[:3, :3]
    T = relative_transform[:3, 3]
    print(f"R={R},T={T}")

    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(
        K_left, dist_left,
        K_right, dist_right,
        image_size,
        R, T,
        alpha=0  # alpha=0 æ„å‘³ç€è£å‰ªå›¾åƒä»¥æ’é™¤æ— æ•ˆåŒºåŸŸï¼›å¯æ ¹æ®éœ€è¦è°ƒæ•´
    )

    # ç”Ÿæˆæ ¡æ­£æ˜ å°„çŸ©é˜µ
    left_map1, left_map2 = cv2.initUndistortRectifyMap(
        K_left, dist_left, R1, P1, image_size, cv2.CV_32FC1)
    right_map1, right_map2 = cv2.initUndistortRectifyMap(
        K_right, dist_right, R2, P2, image_size, cv2.CV_32FC1)

    # å¯¹å·¦å³å›¾åƒè¿›è¡Œé‡æ˜ å°„ï¼Œå¾—åˆ°æ ¡æ­£åçš„å›¾åƒ
    rectified_left = cv2.remap(left_image, left_map1, left_map2, cv2.INTER_LINEAR)
    rectified_right = cv2.remap(right_image, right_map1, right_map2, cv2.INTER_LINEAR)


    # æ˜¾ç¤ºæ ¡æ­£åçš„å›¾åƒä»¥éªŒè¯æ•ˆæœ
    cv2.imshow("Rectified Left", rectified_left)
    cv2.imshow("Rectified Right", rectified_right)
    cv2.imwrite("OpenStereo/RectifiedLeft1.png", rectified_left)
    cv2.imwrite("OpenStereo/RectifiedRight1.png", rectified_right)
    cv2.waitKey(3000)
    cv2.destroyAllWindows()

    return rectified_left,rectified_right


# if __name__ == "__main__":
# #
# #     # x,y,z = get_hmd_forward_vector()
# #     # print(x,y,z)
# #     # #script_st.move_to_pos(-0.3,0.4,-0.3)
# #     # script_st.move_to_pos(-0.1 , 0.05 , -0.5)
# #     # script_st.move_to_pos(-0.1 + x, 0.05 + y, -0.5 + z)
# #
#     script_st.move_to_pos(2.8,0,-2.8)
